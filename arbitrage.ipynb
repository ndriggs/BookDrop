{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keepa\n",
    "import numpy as np\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import pandas as pd\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"api_key.txt\") as key_file :\n",
    "    api_key = key_file.readline().strip()\n",
    "api = keepa.Keepa(api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do a product search to filter out books that may be good to look at\n",
    "book_params = {\n",
    "    'deltaPercent30_USED_gte': 20,\n",
    "    'deltaPercent30_USED_lte': 99,\n",
    "    'deltaPercent90_COUNT_USED_gte': -50,\n",
    "    'deltaPercent90_COUNT_USED_lte': 99,\n",
    "    'avg180_SALES_gte': 0,\n",
    "    'avg180_SALES_lte': 7000000,\n",
    "    'rootCategory': 283155\n",
    "}\n",
    "# don't include list price because there's no way to compare the list price with the used price at this point in the process\n",
    "# have Mark go through the other parameters and see if there's anything he thinks would also be helpful to include"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_params = {\n",
    "    \"avg180_SALES_gte\": 10000,\n",
    "    \"avg180_SALES_lte\": 6000000,\n",
    "    \"current_USED_gte\": 800,\n",
    "    \"current_USED_lte\": 1200,\n",
    "    \"avg30_USED_gte\": 1800,\n",
    "    \"avg30_USED_lte\": 1000000000,\n",
    "    \"current_LISTPRICE_gte\": 5000,\n",
    "    \"current_LISTPRICE_lte\": 100000000,\n",
    "    \"avg180_LISTPRICE_gte\": 5000,\n",
    "    \"avg180_LISTPRICE_lte\": 100000000,\n",
    "    \"rootCategory\": 283155,\n",
    "    \"perPage\": 10\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = api.product_finder(test_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:03<00:00,  3.09it/s]\n"
     ]
    }
   ],
   "source": [
    "asins = ['1888799838',\n",
    "'1111987254',\n",
    "'0769857698',\n",
    "'185617610X',\n",
    "'0521860962',\n",
    "'0387708820',\n",
    "'0072852631',\n",
    "'1943876339',\n",
    "'1580017304',\n",
    "'1269773186']\n",
    "book_data = api.query(asins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:05<00:00,  1.94it/s]\n"
     ]
    }
   ],
   "source": [
    "# now call the api to get the data on all these books\n",
    "book_data = api.query(test[40:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0155510088'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_data[1]['asin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------- THE METRICS --------\n",
    "# Used Count % change from 90 average now to 90 day average a year ago (maybe have it's weight be linear based off the average\n",
    "# of the averages)\n",
    "# Used Count change in number (90 day average to 90 day average)\n",
    "# Current Used Count\n",
    "# Current List Price\n",
    "# Current New Price\n",
    "# Max Trade-in value over the past year\n",
    "# % ROI from current used price + shipping (see below) compared to average \n",
    "# price it sold at (or during peak?) minus Amazon ($10+15%) fees\n",
    "# Residuals of rolling average\n",
    "# Max rolling average (amount made during peak)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO \n",
    "# find the used offer count when it sold\n",
    "# Calculate the value/worth of it to us and expected value ~ compare it with current price\n",
    "# when doing exp val if less than $10 just counts as not selling\n",
    "\n",
    "# for current used price (how much we pay) add $3.99 for below $5.46 and $2 for between that and $10\n",
    "\n",
    "# when "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# when it sold and how much it sold for\n",
    "two_yrs_ago = datetime.datetime.now() - relativedelta(years=2)\n",
    "sell_prices = pd.DataFrame()\n",
    "sell_dates = pd.DataFrame()\n",
    "for book in range(len(book_data)) :\n",
    "    last_two_years = book_data[book]['data']['SALES_time'] > two_yrs_ago\n",
    "    drop_dates_list = []\n",
    "    sell_prices_list = []\n",
    "    for day in np.where(last_two_years)[0] :\n",
    "        if ((book_data[book]['data']['SALES'][day - 1] - \n",
    "            book_data[book]['data']['SALES'][day]) / \n",
    "            (book_data[book]['data']['SALES'][day - 1]) >= .04) :\n",
    "            day_sold = book_data[book]['data']['SALES_time'][day]\n",
    "            drop_dates_list.append(day_sold)\n",
    "            try :\n",
    "                day_sold_index = np.where(book_data[book]['data']['USED_time'] == day_sold)[0][0] - 1\n",
    "            except IndexError :\n",
    "                previous_days = np.where(book_data[book]['data']['USED_time'] < day_sold)\n",
    "                day_sold_index = previous_days[0][-1]\n",
    "            sell_prices_list.append(book_data[book]['data']['USED'][day_sold_index])\n",
    "    drop_dates_df = pd.DataFrame({book_data[book]['asin']:drop_dates_list})\n",
    "    sell_dates = pd.concat([sell_dates, drop_dates_df], ignore_index=True, axis=1)\n",
    "    sell_prices_df = pd.DataFrame({book_data[book]['asin']:sell_prices_list})\n",
    "    sell_prices = pd.concat([sell_prices, sell_prices_df], ignore_index=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# find the rolling 30 day sales total\n",
    "sell_prices = sell_prices.fillna(0) #convert the NaNs to 0s so we can do math with them\n",
    "rolling_averages = pd.DataFrame()\n",
    "for book in range(len(book_data)) :\n",
    "    two_yrs_ago = datetime.datetime.now() - relativedelta(years=2)\n",
    "    two_yrs_30days = two_yrs_ago + datetime.timedelta(days=30)\n",
    "    mving_window = [two_yrs_ago, two_yrs_30days]\n",
    "    rolling_average = []\n",
    "    for day in range(701) : # there's 701 days between the end of the moving window and today\n",
    "        start = sell_dates[book] > mving_window[0]\n",
    "        end = sell_dates[book] < mving_window[1]\n",
    "        window = np.where(start & end)[0]\n",
    "        rolling_average.append(np.sum(sell_prices[book][window]))\n",
    "        for date in range(len(mving_window)) :\n",
    "            mving_window[date] += datetime.timedelta(days=1)\n",
    "    rolling_averages[book] = rolling_average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variance of rolling sales totals (residuals)\n",
    "regr = linear_model.LinearRegression()\n",
    "now = datetime.datetime.now().date()\n",
    "start_date = now + relativedelta(years=-2,days=30) \n",
    "x = np.arange(701).reshape(-1,1)\n",
    "variance = []\n",
    "for book in range(len(book_data)) :\n",
    "    y = rolling_averages[book]\n",
    "    regr.fit(x, y)\n",
    "    score = regr.score(x,y)\n",
    "    y_mean = np.average(y)\n",
    "    sum_sqs = []\n",
    "    for day in range(701) :\n",
    "        sum_sqs.append((rolling_averages[book][day] - y_mean) ** 2)\n",
    "    total_sum_sqs = np.sum(sum_sqs)\n",
    "    residual_sum_sqs = total_sum_sqs * (1 - score)\n",
    "    variance.append(residual_sum_sqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Highest peak amount and date\n",
    "peaks = pd.DataFrame()\n",
    "peak_amount = []\n",
    "peak_end_date = []\n",
    "now = datetime.datetime.now().date()\n",
    "start = now + relativedelta(years=-2,days=30)\n",
    "date_range = pd.date_range(start, now)\n",
    "for book in range(len(book_data)) :\n",
    "    peak = np.amax(rolling_averages[book])\n",
    "    peak_amount.append(peak)\n",
    "    peak_time = np.where(rolling_averages[book] == peak)[0]\n",
    "    peak_end_date.append(date_range[peak_time[-1]])\n",
    "peaks['Peak Amount'] = peak_amount  #### Do we even want to use the total amount it made during peak? \n",
    "# take this part out probably\n",
    "# how can we calculate likelyhood to sell\n",
    "# maybe take this and compare it with the average number of used offers during that time\n",
    "peaks['Peak End Date'] = peak_end_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USED COUNT % change and difference for 90 averages over a year\n",
    "# compute a reimann sum for the step graph, with delta x as 12 hours\n",
    "used_count_avgs = pd.DataFrame()\n",
    "thirty_days_ago = datetime.datetime.now() - datetime.timedelta(days=90)\n",
    "for year in range(2) :    \n",
    "    used_count_avg = []\n",
    "    for book in range(len(book_data)) :\n",
    "        start = thirty_days_ago - (datetime.timedelta(days=365) * year)\n",
    "        total_used_sum = []\n",
    "        for twelve_hours in range(180) :\n",
    "            time = start + (datetime.timedelta(hours=12) * twelve_hours)\n",
    "            current = book_data[book]['data']['COUNT_USED_time'] < time\n",
    "            last_value = book_data[book]['data']['COUNT_USED'][np.where(current)[0][-1]]\n",
    "            current_used_count = 0 if(last_value == -1) else last_value # the data lists -1 where there are really 0 used offers\n",
    "            total_used_sum.append(current_used_count)\n",
    "        used_count_avg.append(np.average(total_used_sum))\n",
    "    used_count_avgs['This year' if(not year) else 'Last year'] = used_count_avg\n",
    "\n",
    "# now use the averages to compute our metrics\n",
    "used_count_metrics = pd.DataFrame()\n",
    "used_count_per_change = []\n",
    "used_count_diff = []\n",
    "for book in range(len(book_data)) :\n",
    "    per_change = (used_count_avgs['This year'][book] - \n",
    "                  used_count_avgs['Last year'][book]) / used_count_avgs['Last year'][book]\n",
    "    used_count_per_change.append(per_change)\n",
    "    used_count_diff.append(used_count_avgs['This year'][book] - used_count_avgs['Last year'][book])\n",
    "used_count_metrics['USED_COUNT percent change'] = used_count_per_change\n",
    "used_count_metrics['USED_COUNT difference'] = used_count_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# % current used price is below average price it sold for after Amazon fees\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0072852631\n",
      "0387708820\n",
      "0521860962\n",
      "0769857698\n",
      "1111987254\n",
      "1269773186\n",
      "1580017304\n",
      "185617610X\n",
      "1888799838\n",
      "1943876339\n"
     ]
    }
   ],
   "source": [
    "for book in range(len(book_data)) :\n",
    "    print(book_data[book]['asin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Date   Price\n",
      " 2015-07-12 13:53:00   $1.00\n",
      " 2015-07-24 07:32:00   $2.00\n",
      " 2015-08-12 09:44:00   $-1.00\n",
      " 2015-09-18 08:14:00   $1.00\n",
      " 2015-09-30 08:21:00   $3.00\n",
      " 2015-10-06 10:17:00   $2.00\n",
      " 2015-11-06 16:38:00   $3.00\n",
      " 2015-12-16 19:35:00   $2.00\n",
      " 2015-12-30 12:55:00   $3.00\n",
      " 2016-01-04 22:23:00   $4.00\n",
      " 2016-01-07 00:06:00   $3.00\n",
      " 2016-01-09 22:14:00   $4.00\n",
      " 2016-01-16 03:17:00   $5.00\n",
      " 2016-01-20 17:48:00   $6.00\n",
      " 2016-01-25 01:09:00   $5.00\n",
      " 2016-01-28 17:53:00   $4.00\n",
      " 2016-01-29 04:21:00   $3.00\n",
      " 2016-05-03 17:20:00   $2.00\n",
      " 2016-05-05 17:43:00   $1.00\n",
      " 2016-05-19 20:19:00   $2.00\n",
      " 2016-06-04 00:42:00   $1.00\n",
      " 2016-06-05 19:10:00   $2.00\n",
      " 2016-06-15 18:52:00   $3.00\n",
      " 2016-06-21 09:20:00   $4.00\n",
      " 2016-07-20 12:08:00   $5.00\n",
      " 2016-07-27 19:36:00   $4.00\n",
      " 2016-08-05 20:10:00   $3.00\n",
      " 2016-08-12 18:24:00   $2.00\n",
      " 2016-08-17 01:24:00   $1.00\n",
      " 2016-08-23 12:16:00   $-1.00\n",
      " 2016-08-27 07:08:00   $1.00\n",
      " 2016-09-01 02:24:00   $-1.00\n",
      " 2016-09-20 03:24:00   $1.00\n",
      " 2016-10-31 19:46:00   $2.00\n",
      " 2016-11-16 16:04:00   $1.00\n",
      " 2016-12-17 23:36:00   $-1.00\n",
      " 2016-12-19 03:28:00   $1.00\n",
      " 2016-12-31 11:12:00   $2.00\n",
      " 2017-01-11 18:32:00   $1.00\n",
      " 2017-01-19 00:36:00   $-1.00\n",
      " 2017-01-21 03:24:00   $1.00\n",
      " 2017-01-23 16:10:00   $-1.00\n",
      " 2017-02-04 16:30:00   $1.00\n",
      " 2017-02-22 18:06:00   $-1.00\n",
      " 2017-03-14 21:48:00   $1.00\n",
      " 2017-05-17 23:00:00   $-1.00\n",
      " 2017-11-13 20:20:00   $1.00\n",
      " 2017-11-19 09:20:00   $-1.00\n",
      " 2017-12-15 22:00:00   $1.00\n",
      " 2018-01-21 07:00:00   $-1.00\n",
      " 2018-04-18 12:28:00   $1.00\n",
      " 2018-04-20 01:24:00   $-1.00\n",
      " 2018-05-04 11:56:00   $1.00\n",
      " 2018-05-08 21:28:00   $-1.00\n",
      " 2018-06-17 19:08:00   $1.00\n",
      " 2018-08-02 09:20:00   $2.00\n",
      " 2018-08-22 00:52:00   $3.00\n",
      " 2018-08-25 12:16:00   $2.00\n",
      " 2018-08-27 17:48:00   $1.00\n",
      " 2018-09-08 03:20:00   $-1.00\n",
      " 2018-09-25 09:04:00   $1.00\n",
      " 2018-10-25 23:48:00   $-1.00\n",
      " 2018-10-31 15:28:00   $1.00\n",
      " 2018-11-07 02:10:00   $-1.00\n",
      " 2019-03-19 15:12:00   $1.00\n",
      " 2019-05-07 05:52:00   $-1.00\n",
      " 2019-05-09 06:16:00   $2.00\n",
      " 2019-05-10 15:24:00   $3.00\n",
      " 2019-05-12 09:04:00   $2.00\n",
      " 2019-05-12 14:50:00   $3.00\n",
      " 2019-05-12 21:30:00   $2.00\n",
      " 2019-05-14 00:24:00   $-1.00\n",
      " 2019-05-29 07:38:00   $2.00\n",
      " 2019-06-07 05:32:00   $3.00\n",
      " 2019-06-11 23:40:00   $4.00\n",
      " 2019-06-13 16:00:00   $5.00\n",
      " 2019-06-16 17:24:00   $4.00\n",
      " 2019-07-07 20:20:00   $3.00\n",
      " 2019-07-08 15:48:00   $4.00\n",
      " 2019-07-14 08:28:00   $3.00\n",
      " 2019-07-20 01:14:00   $4.00\n",
      " 2019-07-22 20:26:00   $3.00\n",
      " 2019-07-25 08:14:00   $4.00\n",
      " 2019-07-28 06:36:00   $5.00\n",
      " 2019-07-29 01:32:00   $4.00\n",
      " 2019-08-08 01:04:00   $3.00\n",
      " 2019-08-08 22:08:00   $4.00\n",
      " 2019-08-12 18:24:00   $5.00\n",
      " 2019-08-17 20:22:00   $6.00\n",
      " 2019-08-25 23:30:00   $5.00\n",
      " 2019-08-31 22:16:00   $2.00\n",
      " 2019-09-01 19:00:00   $1.00\n",
      " 2019-09-03 11:12:00   $-1.00\n",
      " 2019-09-04 04:52:00   $2.00\n",
      " 2019-09-10 18:10:00   $1.00\n",
      " 2019-09-13 07:44:00   $-1.00\n",
      " 2019-09-16 17:28:00   $1.00\n",
      " 2019-09-19 05:50:00   $2.00\n",
      " 2019-09-19 20:48:00   $1.00\n",
      " 2019-09-21 00:00:00   $2.00\n",
      " 2019-09-21 15:00:00   $1.00\n",
      " 2019-09-21 16:56:00   $2.00\n",
      " 2019-09-23 00:08:00   $1.00\n",
      " 2019-09-23 17:44:00   $2.00\n",
      " 2019-09-25 15:12:00   $3.00\n",
      " 2019-09-26 22:12:00   $2.00\n",
      " 2019-09-29 13:36:00   $4.00\n",
      " 2019-10-05 03:32:00   $5.00\n",
      " 2019-10-05 13:12:00   $4.00\n",
      " 2019-10-15 19:20:00   $3.00\n",
      " 2019-10-16 20:34:00   $5.00\n",
      " 2019-10-23 19:20:00   $6.00\n",
      " 2019-10-25 11:28:00   $5.00\n",
      " 2019-10-28 21:44:00   $6.00\n",
      " 2019-10-30 20:08:00   $7.00\n",
      " 2019-11-01 09:44:00   $6.00\n",
      " 2019-11-07 12:28:00   $7.00\n",
      " 2019-11-08 05:22:00   $6.00\n",
      " 2019-11-13 02:42:00   $5.00\n",
      " 2019-11-13 11:40:00   $6.00\n",
      " 2019-11-18 22:36:00   $7.00\n",
      " 2019-12-04 03:58:00   $6.00\n",
      " 2019-12-04 07:48:00   $7.00\n",
      " 2019-12-20 23:40:00   $8.00\n",
      " 2019-12-22 22:36:00   $7.00\n",
      " 2019-12-27 18:18:00   $8.00\n",
      " 2019-12-27 23:28:00   $7.00\n",
      " 2019-12-28 05:28:00   $8.00\n",
      " 2020-01-02 10:02:00   $7.00\n",
      " 2020-01-02 14:52:00   $8.00\n",
      " 2020-01-06 05:12:00   $7.00\n",
      " 2020-01-06 10:24:00   $8.00\n",
      " 2020-01-06 23:54:00   $9.00\n",
      " 2020-01-07 23:32:00   $8.00\n",
      " 2020-01-09 19:04:00   $7.00\n",
      " 2020-01-09 23:28:00   $8.00\n",
      " 2020-01-12 02:24:00   $7.00\n",
      " 2020-01-12 09:48:00   $8.00\n",
      " 2020-01-13 04:00:00   $9.00\n",
      " 2020-01-14 16:00:00   $8.00\n",
      " 2020-01-16 00:24:00   $7.00\n",
      " 2020-01-18 01:34:00   $8.00\n",
      " 2020-01-18 03:20:00   $7.00\n",
      " 2020-01-18 05:24:00   $8.00\n",
      " 2020-01-18 13:20:00   $9.00\n",
      " 2020-01-26 14:24:00   $8.00\n",
      " 2020-01-26 16:32:00   $9.00\n",
      " 2020-01-30 16:40:00   $8.00\n",
      " 2020-01-31 20:16:00   $7.00\n",
      " 2020-02-01 06:52:00   $6.00\n",
      " 2020-02-01 11:00:00   $7.00\n",
      " 2020-02-01 17:58:00   $8.00\n",
      " 2020-02-01 23:00:00   $7.00\n",
      " 2020-02-02 08:44:00   $6.00\n",
      " 2020-02-02 14:04:00   $7.00\n",
      " 2020-02-03 14:46:00   $6.00\n",
      " 2020-02-03 17:14:00   $7.00\n",
      " 2020-02-03 20:52:00   $8.00\n",
      " 2020-02-04 05:36:00   $9.00\n",
      " 2020-02-06 13:36:00   $8.00\n",
      " 2020-02-07 02:32:00   $7.00\n",
      " 2020-02-07 04:58:00   $8.00\n",
      " 2020-02-08 13:04:00   $7.00\n",
      " 2020-02-08 21:16:00   $8.00\n",
      " 2020-02-10 14:10:00   $9.00\n",
      " 2020-02-11 07:08:00   $8.00\n",
      " 2020-02-11 10:30:00   $9.00\n",
      " 2020-02-12 00:08:00   $8.00\n",
      " 2020-02-12 06:00:00   $6.00\n",
      " 2020-02-12 09:36:00   $7.00\n",
      " 2020-02-12 12:00:00   $8.00\n",
      " 2020-02-13 12:02:00   $7.00\n",
      " 2020-02-13 14:04:00   $6.00\n",
      " 2020-02-13 17:12:00   $7.00\n",
      " 2020-02-13 20:44:00   $8.00\n",
      " 2020-02-20 11:34:00   $7.00\n",
      " 2020-02-20 16:50:00   $8.00\n",
      " 2020-02-20 19:08:00   $7.00\n",
      " 2020-02-20 23:36:00   $8.00\n",
      " 2020-02-26 22:20:00   $7.00\n",
      " 2020-02-27 02:40:00   $8.00\n",
      " 2020-03-02 06:56:00   $7.00\n",
      " 2020-03-02 10:44:00   $8.00\n",
      " 2020-03-05 08:48:00   $7.00\n",
      " 2020-03-05 13:20:00   $8.00\n",
      " 2020-03-12 18:48:00   $7.00\n",
      " 2020-03-12 20:36:00   $8.00\n",
      " 2020-03-14 08:38:00   $7.00\n",
      " 2020-03-14 14:00:00   $8.00\n",
      " 2020-03-27 07:48:00   $7.00\n"
     ]
    }
   ],
   "source": [
    "# Access new price history and associated time data\n",
    "newprice = book_data[5]['data']['COUNT_USED']\n",
    "newpricetime = book_data[5]['data']['COUNT_USED_time']\n",
    "\n",
    "# print the first 10 prices\n",
    "print('%20s   %s' % ('Date', 'Price'))\n",
    "for i in range(len(newpricetime[10:])):\n",
    "    print('%20s   $%.2f' % (newpricetime[i], newprice[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
