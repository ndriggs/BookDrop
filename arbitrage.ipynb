{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keepa\n",
    "import numpy as np\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import pandas as pd\n",
    "from sklearn import linear_model\n",
    "import scipy.stats as stats\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"api_key.txt\") as key_file :\n",
    "    api_key = key_file.readline().strip()\n",
    "api = keepa.Keepa(api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_searches = 21\n",
    "search_params = [{}] * num_searches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_params[0] = {\n",
    "    \"avg180_SALES_gte\": 0,\n",
    "    \"avg180_SALES_lte\": 7000000,\n",
    "    \"current_USED_gte\": 0,\n",
    "    \"current_USED_lte\": 749,\n",
    "    \"avg30_USED_gte\": 1200,\n",
    "    \"avg30_USED_lte\": 1000000000,\n",
    "    \"current_LISTPRICE_gte\": 5000,\n",
    "    \"current_LISTPRICE_lte\": 100000000,\n",
    "    \"avg180_LISTPRICE_gte\": 5000,\n",
    "    \"avg180_LISTPRICE_lte\": 100000000,\n",
    "    \"rootCategory\": 283155,\n",
    "    \"perPage\": 10000\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_params[1] = {\n",
    "    \"current_SALES_gte\": 0,\n",
    "    \"current_SALES_lte\": 7000000,\n",
    "    \"avg30_SALES_gte\": 0,\n",
    "    \"avg30_SALES_lte\": 7000000,\n",
    "    \"avg90_SALES_gte\": 0,\n",
    "    \"avg90_SALES_lte\": 7000000,\n",
    "    \"avg180_SALES_gte\": 0,\n",
    "    \"avg180_SALES_lte\": 7000000,\n",
    "    \"current_USED_gte\": 0,\n",
    "    \"current_USED_lte\": 350,\n",
    "    \"avg180_USED_gte\": 500,\n",
    "    \"avg180_USED_lte\": 1000000000,\n",
    "    \"current_LISTPRICE_gte\": 4000,\n",
    "    \"current_LISTPRICE_lte\": 100000000,\n",
    "    \"avg180_TRADE_IN_gte\": 0,\n",
    "    \"avg180_TRADE_IN_lte\": 1000000000,\n",
    "    \"rootCategory\": 283155,\n",
    "    \"perPage\": 10000\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_params[2] = {\n",
    "    \"avg180_SALES_gte\": 0,\n",
    "    \"avg180_SALES_lte\": 2500000,\n",
    "    \"current_USED_gte\": 0,\n",
    "    \"current_USED_lte\": 469,\n",
    "    \"avg90_USED_gte\": 250,\n",
    "    \"avg90_USED_lte\": 1000000000,\n",
    "    \"avg180_USED_gte\": 700,\n",
    "    \"avg180_USED_lte\": 1000000000,\n",
    "    \"current_LISTPRICE_gte\": 4800,\n",
    "    \"current_LISTPRICE_lte\": 10000000,\n",
    "    \"rootCategory\": 283155,\n",
    "    \"perPage\": 10000\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_params[3] = {\n",
    "    \"avg180_SALES_gte\": 0,\n",
    "    \"avg180_SALES_lte\": 2500000,\n",
    "    \"current_USED_gte\": 470,\n",
    "    \"current_USED_lte\": 749,\n",
    "    \"avg180_USED_gte\": 750,\n",
    "    \"avg180_USED_lte\": 1000000000,\n",
    "    \"current_LISTPRICE_gte\": 5000,\n",
    "    \"current_LISTPRICE_lte\": 100000000,\n",
    "    \"rootCategory\": 283155,\n",
    "    \"avg90_USED_gte\": 450,\n",
    "    \"avg90_USED_lte\": 1000000000,\n",
    "    \"perPage\": 10000\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_params[4] = {\n",
    "    \"avg180_SALES_gte\": 2510000,\n",
    "    \"avg180_SALES_lte\": 5000000,\n",
    "    \"current_USED_gte\": 0,\n",
    "    \"current_USED_lte\": 749,\n",
    "    \"avg30_USED_gte\": 1000,\n",
    "    \"avg30_USED_lte\": 100000000,\n",
    "    \"avg90_USED_gte\": 3000,\n",
    "    \"avg90_USED_lte\": 100000000,\n",
    "    \"avg180_USED_gte\": 4000,\n",
    "    \"avg180_USED_lte\": 100000000,\n",
    "    \"rootCategory\": 283155,\n",
    "    \"current_LISTPRICE_gte\": 6000,\n",
    "    \"current_LISTPRICE_lte\": 1000000000,\n",
    "    \"perPage\": 10000\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_params[5] = {\n",
    "    \"avg180_SALES_gte\": 5000001,\n",
    "    \"avg180_SALES_lte\": 12000000,\n",
    "    \"current_USED_gte\": 0,\n",
    "    \"current_USED_lte\": 749,\n",
    "    \"avg30_USED_gte\": 2500,\n",
    "    \"avg30_USED_lte\": 1000000000,\n",
    "    \"avg90_USED_gte\": 5000,\n",
    "    \"avg90_USED_lte\": 1000000000,\n",
    "    \"avg180_USED_gte\": 7000,\n",
    "    \"avg180_USED_lte\": 1000000000,\n",
    "    \"current_LISTPRICE_gte\": 9900,\n",
    "    \"current_LISTPRICE_lte\": 1000000000,\n",
    "    \"perPage\": 10000\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_params[6] = {\n",
    "    \"avg180_SALES_gte\": 0,\n",
    "    \"avg180_SALES_lte\": 4000000,\n",
    "    \"current_USED_gte\": 750,\n",
    "    \"current_USED_lte\": 1200,\n",
    "    \"avg30_USED_gte\": 1500,\n",
    "    \"avg30_USED_lte\": 100000000,\n",
    "    \"avg90_USED_gte\": 1200,\n",
    "    \"avg90_USED_lte\": 100000000,\n",
    "    \"avg180_USED_gte\": 1200,\n",
    "    \"avg180_USED_lte\": 100000000,\n",
    "    \"current_LISTPRICE_gte\": 6000,\n",
    "    \"current_LISTPRICE_lte\": 100000000,\n",
    "    \"rootCategory\": 283155,\n",
    "    \"perPage\": 10000\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_params[7] = {\n",
    "    \"avg180_SALES_gte\": 0,\n",
    "    \"avg180_SALES_lte\": 4000000,\n",
    "    \"current_USED_gte\": 1201,\n",
    "    \"current_USED_lte\": 1600,\n",
    "    \"avg30_USED_gte\": 2000,\n",
    "    \"avg30_USED_lte\": 100000000,\n",
    "    \"avg90_USED_gte\": 1600,\n",
    "    \"avg90_USED_lte\": 100000000,\n",
    "    \"avg180_USED_gte\": 1600,\n",
    "    \"avg180_USED_lte\": 100000000,\n",
    "    \"current_LISTPRICE_gte\": 6500,\n",
    "    \"current_LISTPRICE_lte\": 100000000,\n",
    "    \"rootCategory\": 283155,\n",
    "    \"perPage\": 10000\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_params[8] = {\n",
    "    \"avg180_SALES_gte\": 0,\n",
    "    \"avg180_SALES_lte\": 10000000,\n",
    "    \"current_USED_gte\": 750,\n",
    "    \"current_USED_lte\": 1200,\n",
    "    \"avg30_USED_gte\": 700,\n",
    "    \"avg30_USED_lte\": 100000000,\n",
    "    \"avg90_USED_gte\": 700,\n",
    "    \"avg90_USED_lte\": 100000000,\n",
    "    \"avg180_USED_gte\": 1500,\n",
    "    \"avg180_USED_lte\": 100000000,\n",
    "    \"current_LISTPRICE_gte\": 6000,\n",
    "    \"current_LISTPRICE_lte\": 100000000,\n",
    "    \"avg180_TRADE_IN_gte\": 0,\n",
    "    \"avg180_TRADE_IN_lte\": 100000000,\n",
    "    \"rootCategory\": 283155,\n",
    "    \"perPage\": 10000\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_params[9] = {\n",
    "    \"avg180_SALES_gte\": 0,\n",
    "    \"avg180_SALES_lte\": 1000000,\n",
    "    \"current_USED_gte\": 1201,\n",
    "    \"current_USED_lte\": 2000,\n",
    "    \"avg30_USED_gte\": 1200,\n",
    "    \"avg30_USED_lte\": 100000000,\n",
    "    \"avg90_USED_gte\": 1200,\n",
    "    \"avg90_USED_lte\": 100000000,\n",
    "    \"avg180_USED_gte\": 2000,\n",
    "    \"avg180_USED_lte\": 100000000,\n",
    "    \"current_LISTPRICE_gte\": 7000,\n",
    "    \"current_LISTPRICE_lte\": 100000000,\n",
    "    \"avg180_TRADE_IN_gte\": 0,\n",
    "    \"avg180_TRADE_IN_lte\": 100000000,\n",
    "    \"rootCategory\": 283155,\n",
    "    \"perPage\": 10000\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_params[10] = {\n",
    "    \"avg180_SALES_gte\": 0,\n",
    "    \"avg180_SALES_lte\": 4500000,\n",
    "    \"current_USED_gte\": 750,\n",
    "    \"current_USED_lte\": 2000,\n",
    "    \"avg180_USED_gte\": 4000,\n",
    "    \"avg180_USED_lte\": 1000000000,\n",
    "    \"current_LISTPRICE_gte\": 6000,\n",
    "    \"current_LISTPRICE_lte\": 100000000,\n",
    "    \"rootCategory\": 283155,\n",
    "    \"perPage\": 10000\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_params[11] = {\n",
    "    \"avg180_SALES_gte\": 0,\n",
    "    \"avg180_SALES_lte\": 4000000,\n",
    "    \"current_USED_gte\": 2000,\n",
    "    \"current_USED_lte\": 2500,\n",
    "    \"avg30_USED_gte\": 2600,\n",
    "    \"avg30_USED_lte\": 100000000,\n",
    "    \"current_LISTPRICE_gte\": 8000,\n",
    "    \"current_LISTPRICE_lte\": 10000000,\n",
    "    \"rootCategory\": 283155,\n",
    "    \"perPage\": 10000\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_params[12] = {\n",
    "    \"avg180_SALES_gte\": 0,\n",
    "    \"avg180_SALES_lte\": 4000000,\n",
    "    \"current_USED_gte\": 2501,\n",
    "    \"current_USED_lte\": 3000,\n",
    "    \"avg30_USED_gte\": 3100,\n",
    "    \"avg30_USED_lte\": 100000000,\n",
    "    \"current_LISTPRICE_gte\": 8000,\n",
    "    \"current_LISTPRICE_lte\": 10000000,\n",
    "    \"rootCategory\": 283155,\n",
    "    \"perPage\": 100\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_params[13] = {\n",
    "    \"avg180_SALES_gte\": 0,\n",
    "    \"avg180_SALES_lte\": 4000000,\n",
    "    \"current_USED_gte\": 3001,\n",
    "    \"current_USED_lte\": 3500,\n",
    "    \"avg30_USED_gte\": 3600,\n",
    "    \"avg30_USED_lte\": 100000000,\n",
    "    \"current_LISTPRICE_gte\": 9000,\n",
    "    \"current_LISTPRICE_lte\": 10000000,\n",
    "    \"rootCategory\": 283155,\n",
    "    \"perPage\": 10000\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_params[14] = {\n",
    "    \"avg180_SALES_gte\": 0,\n",
    "    \"avg180_SALES_lte\": 4000000,\n",
    "    \"current_USED_gte\": 3501,\n",
    "    \"current_USED_lte\": 4000,\n",
    "    \"avg30_USED_gte\": 4100,\n",
    "    \"avg30_USED_lte\": 100000000,\n",
    "    \"current_LISTPRICE_gte\": 9000,\n",
    "    \"current_LISTPRICE_lte\": 10000000,\n",
    "    \"rootCategory\": 283155,\n",
    "    \"perPage\": 10000\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_params[15] = {\n",
    "    \"avg180_SALES_gte\": 0,\n",
    "    \"avg180_SALES_lte\": 4000000,\n",
    "    \"current_USED_gte\": 4001,\n",
    "    \"current_USED_lte\": 4500,\n",
    "    \"avg30_USED_gte\": 4600,\n",
    "    \"avg30_USED_lte\": 100000000,\n",
    "    \"current_LISTPRICE_gte\": 10000,\n",
    "    \"current_LISTPRICE_lte\": 10000000,\n",
    "    \"rootCategory\": 283155,\n",
    "    \"perPage\": 10000\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_params[16] = {\n",
    "    \"avg180_SALES_gte\": 0,\n",
    "    \"avg180_SALES_lte\": 4000000,\n",
    "    \"current_USED_gte\": 4501,\n",
    "    \"current_USED_lte\": 5000,\n",
    "    \"avg30_USED_gte\": 5100,\n",
    "    \"avg30_USED_lte\": 100000000,\n",
    "    \"current_LISTPRICE_gte\": 11000,\n",
    "    \"current_LISTPRICE_lte\": 10000000,\n",
    "    \"rootCategory\": 283155,\n",
    "    \"perPage\": 10000\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_params[17] = {\n",
    "    \"avg180_SALES_gte\": 0,\n",
    "    \"avg180_SALES_lte\": 8000000,\n",
    "    \"current_USED_gte\": 2000,\n",
    "    \"current_USED_lte\": 3000,\n",
    "    \"avg180_USED_gte\": 3200,\n",
    "    \"avg180_USED_lte\": 100000000,\n",
    "    \"current_LISTPRICE_gte\": 8000,\n",
    "    \"current_LISTPRICE_lte\": 1000000000,\n",
    "    \"avg180_TRADE_IN_gte\": 0,\n",
    "    \"avg180_TRADE_IN_lte\": 1000000000,\n",
    "    \"rootCategory\": 283155,\n",
    "    \"perPage\": 10000\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_params[18] = {\n",
    "    \"avg180_SALES_gte\": 0,\n",
    "    \"avg180_SALES_lte\": 8000000,\n",
    "    \"current_USED_gte\": 3000,\n",
    "    \"current_USED_lte\": 4000,\n",
    "    \"avg180_USED_gte\": 4400,\n",
    "    \"avg180_USED_lte\": 100000000,\n",
    "    \"current_LISTPRICE_gte\": 10000,\n",
    "    \"current_LISTPRICE_lte\": 1000000000,\n",
    "    \"avg180_TRADE_IN_gte\": 0,\n",
    "    \"avg180_TRADE_IN_lte\": 1000000000,\n",
    "    \"rootCategory\": 283155,\n",
    "    \"perPage\": 10000\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_params[19] = {\n",
    "    \"avg180_SALES_gte\": 0,\n",
    "    \"avg180_SALES_lte\": 8000000,\n",
    "    \"current_USED_gte\": 4001,\n",
    "    \"current_USED_lte\": 5000,\n",
    "    \"avg180_USED_gte\": 5400,\n",
    "    \"avg180_USED_lte\": 100000000,\n",
    "    \"current_LISTPRICE_gte\": 11000,\n",
    "    \"current_LISTPRICE_lte\": 1000000000,\n",
    "    \"avg180_TRADE_IN_gte\": 0,\n",
    "    \"avg180_TRADE_IN_lte\": 1000000000,\n",
    "    \"rootCategory\": 283155,\n",
    "    \"perPage\": 10000\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_params[20] = {\n",
    "    \"avg180_SALES_gte\": 0,\n",
    "    \"avg180_SALES_lte\": 4500000,\n",
    "    \"current_USED_gte\": 2000,\n",
    "    \"current_USED_lte\": 5000,\n",
    "    \"avg180_USED_gte\": 8000,\n",
    "    \"avg180_USED_lte\": 100000000,\n",
    "    \"current_LISTPRICE_gte\": 12000,\n",
    "    \"current_LISTPRICE_lte\": 1000000000,\n",
    "    \"rootCategory\": 283155,\n",
    "    \"perPage\": 10000\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "asins = [[] for search in range(num_searches)]\n",
    "for search in range(num_searches) :\n",
    "    asins[search] = api.product_finder(search_params[search])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17121"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asins = list(itertools.chain.from_iterable(asins))\n",
    "asins = list(dict.fromkeys(asins))\n",
    "len(asins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14548/14548 [31:26<00:00, 11.33it/s]"
     ]
    }
   ],
   "source": [
    "book_data = api.query(asins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-2fa7060e01cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0mused_counts_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdo_nothing\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mbook_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbook\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'COUNT_USED'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mday_sold_used_count\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mdrop_dates_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mbook_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbook\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'asin'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mdrop_dates_list\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0msell_dates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msell_dates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop_dates_df\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m     \u001b[0msell_prices_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mbook_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbook\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'asin'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0msell_prices_list\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0msell_prices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msell_prices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msell_prices_df\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/c/Users/natha/Documents/TourdeFinance/trading_env/lib/python3.6/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[0mverify_integrity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverify_integrity\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m         \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m         \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m     )\n\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/c/Users/natha/Documents/TourdeFinance/trading_env/lib/python3.6/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0;31m# consolidate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 360\u001b[0;31m             \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_consolidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    361\u001b[0m             \u001b[0mndims\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/c/Users/natha/Documents/TourdeFinance/trading_env/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_consolidate\u001b[0;34m(self, inplace)\u001b[0m\n\u001b[1;32m   5363\u001b[0m         \u001b[0minplace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_bool_kwarg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"inplace\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5364\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5365\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5366\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5367\u001b[0m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconsolidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/c/Users/natha/Documents/TourdeFinance/trading_env/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_consolidate_inplace\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   5345\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconsolidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5347\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_protect_consolidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5348\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5349\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_consolidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/c/Users/natha/Documents/TourdeFinance/trading_env/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_protect_consolidate\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m   5334\u001b[0m         \"\"\"\n\u001b[1;32m   5335\u001b[0m         \u001b[0mblocks_before\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5336\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5337\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mblocks_before\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5338\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_clear_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/c/Users/natha/Documents/TourdeFinance/trading_env/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mf\u001b[0;34m()\u001b[0m\n\u001b[1;32m   5343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5344\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5345\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconsolidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5347\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_protect_consolidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/c/Users/natha/Documents/TourdeFinance/trading_env/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   5285\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5286\u001b[0m             \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5287\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5288\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5289\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# when it sold, how much it sold for, and the number of used offers at that time\n",
    "two_yrs_ago = datetime.datetime.now() - relativedelta(years=2)\n",
    "sell_prices = pd.DataFrame()\n",
    "sell_dates = pd.DataFrame()\n",
    "used_counts = pd.DataFrame()\n",
    "for book in range(len(book_data)) :\n",
    "    last_two_years = book_data[book]['data']['SALES_time'] > two_yrs_ago\n",
    "    drop_dates_list = []\n",
    "    sell_prices_list = []\n",
    "    used_counts_list = []\n",
    "    for day in np.where(last_two_years)[0] :\n",
    "        if ((book_data[book]['data']['SALES'][day - 1] - \n",
    "            book_data[book]['data']['SALES'][day]) / \n",
    "            (book_data[book]['data']['SALES'][day - 1]) >= .04) :\n",
    "            day_sold = book_data[book]['data']['SALES_time'][day]\n",
    "            drop_dates_list.append(day_sold)\n",
    "            new = False\n",
    "            try :\n",
    "                day_sold_Used_index = np.where(book_data[book]['data']['USED_time'] == day_sold)[0][0] - 1 #if (np.where(book_data[book]['data']['USED_time'] == day_sold)[0][0] != 0) else 0\n",
    "            except IndexError :\n",
    "                try :\n",
    "                    day_sold_Used_index = np.where(book_data[book]['data']['USED_time'] < day_sold)[0][-1]\n",
    "                except IndexError :\n",
    "                    day_sold_Used_index = np.where(book_data[book]['data']['NEW_time'] < day_sold)[0][-1]\n",
    "                    new = True\n",
    "            sell_prices_list.append(book_data[book]['data']['NEW' if new else 'USED'][day_sold_Used_index])  \n",
    "            do_nothing = False\n",
    "            try :\n",
    "                day_sold_used_count = np.where(book_data[book]['data']['COUNT_USED_time'] == day_sold)[0][0] - 1 #if (np.where(book_data[book]['data']['COUNT_USED_time'] == day_sold)[0][0] != 0) else 0\n",
    "            except IndexError :\n",
    "                try :\n",
    "                    day_sold_used_count = np.where(book_data[book]['data']['COUNT_USED_time'] < day_sold)[0][-1]\n",
    "                except IndexError :\n",
    "                    do_nothing = True\n",
    "            used_counts_list.append(0 if do_nothing else book_data[book]['data']['COUNT_USED'][day_sold_used_count])\n",
    "    drop_dates_df = pd.DataFrame({book_data[book]['asin']:drop_dates_list})\n",
    "    sell_dates = pd.concat([sell_dates, drop_dates_df], ignore_index=True, axis=1)\n",
    "    sell_prices_df = pd.DataFrame({book_data[book]['asin']:sell_prices_list})\n",
    "    sell_prices = pd.concat([sell_prices, sell_prices_df], ignore_index=True, axis=1)\n",
    "    used_counts_df = pd.DataFrame({book_data[book]['asin']:used_counts_list})\n",
    "    used_counts = pd.concat([used_counts, used_counts_df], ignore_index=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change anytime it sold for less than $11.77 to counting it as not selling at all\n",
    "for column in sell_prices.columns :\n",
    "    for row in sell_prices.index :\n",
    "        if(sell_prices[column][row] < 11.77) :\n",
    "            sell_prices.iloc[row, column] = 0\n",
    "            used_counts.iloc[row, column] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# find the rolling 30 day sales total\n",
    "sell_prices = sell_prices.fillna(0) #convert the NaNs to 0s so we can do math with them\n",
    "used_counts = used_counts.fillna(0)\n",
    "rolling_averages = pd.DataFrame()\n",
    "num_sold = pd.DataFrame()\n",
    "used_count_avg = pd.DataFrame()\n",
    "for book in range(len(book_data)) :\n",
    "    two_yrs_ago = datetime.datetime.now() - relativedelta(years=2)\n",
    "    two_yrs_30days = two_yrs_ago + datetime.timedelta(days=30)\n",
    "    mving_window = [two_yrs_ago, two_yrs_30days]\n",
    "    rolling_average = []\n",
    "    books_sold = []\n",
    "    used_cnt = []\n",
    "    for day in range(701) : # there's 701 days between the end of the moving window and today\n",
    "        start = sell_dates[book] > mving_window[0]\n",
    "        end = sell_dates[book] < mving_window[1]\n",
    "        window = np.where(start & end)[0]\n",
    "        rolling_average.append(np.sum(sell_prices[book][window]))\n",
    "        books_sold.append(np.count_nonzero(sell_prices[book][window]))\n",
    "        used_cnt.append(np.average(used_counts[book][window]) if len(used_counts[book][window]) != 0 else 0)\n",
    "        for date in range(len(mving_window)) :\n",
    "            mving_window[date] += datetime.timedelta(days=1)\n",
    "    rolling_averages[book] = rolling_average\n",
    "    num_sold[book] = books_sold\n",
    "    used_count_avg[book] = used_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variance of rolling sales totals (residuals)\n",
    "regr = linear_model.LinearRegression()\n",
    "now = datetime.datetime.now().date()\n",
    "start_date = now + relativedelta(years=-2,days=30) \n",
    "x = np.arange(701).reshape(-1,1)\n",
    "variance = []\n",
    "for book in range(len(book_data)) :\n",
    "    y = rolling_averages[book]\n",
    "    regr.fit(x, y)\n",
    "    score = regr.score(x,y)\n",
    "    y_mean = np.average(y)\n",
    "    sum_sqs = []\n",
    "    for day in range(701) :\n",
    "        sum_sqs.append((rolling_averages[book][day] - y_mean) ** 2)\n",
    "    total_sum_sqs = np.sum(sum_sqs)\n",
    "    residual_sum_sqs = total_sum_sqs * (1 - score)\n",
    "    variance.append(residual_sum_sqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Highest peak amount and date\n",
    "peaks = pd.DataFrame()\n",
    "peak_amount = []\n",
    "peak_end_date = []\n",
    "peak_num_sold = []\n",
    "peak_used_avg = []\n",
    "peak_avg_price = []\n",
    "now = datetime.datetime.now().date()\n",
    "start = now + relativedelta(years=-2,days=30)\n",
    "date_range = pd.date_range(start, now)\n",
    "for book in range(len(book_data)) :\n",
    "    peak = np.amax(rolling_averages[book][335:]) # only look at past year\n",
    "    peak_amount.append(peak)\n",
    "    peak_time = np.where(rolling_averages[book] == peak)[0]\n",
    "    peak_end_date.append(date_range[peak_time[-1]])\n",
    "    peak_num_sold.append(num_sold[book][peak_time[-1]])\n",
    "    peak_used_avg.append(used_count_avg[book][peak_time[-1]])\n",
    "    peak_avg_price.append(peak_amount[book] / peak_num_sold[book])\n",
    "peaks['Peak Amount'] = peak_amount  #### Do we even want to use the total amount it made during peak? \n",
    "# take this part out probably\n",
    "# how can we calculate likelyhood to sell\n",
    "# maybe take this and compare it with the average number of used offers during that time\n",
    "peaks['Peak End Date'] = peak_end_date\n",
    "peaks['Num Sold During Peak'] = peak_num_sold\n",
    "peaks['Average # of Used Offers'] = peak_used_avg\n",
    "peaks['Average Price'] = peak_avg_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USED COUNT % change and difference for 90 averages over a year\n",
    "# compute a reimann sum for the step graph, with delta x as 12 hours\n",
    "used_count_avgs = pd.DataFrame()\n",
    "thirty_days_ago = datetime.datetime.now() - datetime.timedelta(days=90)\n",
    "for year in range(2) :    \n",
    "    used_count_avg = []\n",
    "    for book in range(len(book_data)) :\n",
    "        start = thirty_days_ago - (datetime.timedelta(days=365) * year)\n",
    "        total_used_sum = []\n",
    "        for twelve_hours in range(180) :\n",
    "            time = start + (datetime.timedelta(hours=12) * twelve_hours)\n",
    "            current = book_data[book]['data']['COUNT_USED_time'] < time\n",
    "            last_value = book_data[book]['data']['COUNT_USED'][np.where(current)[0][-1]]\n",
    "            current_used_count = 0 if(last_value == -1) else last_value # the data lists -1 where there are really 0 used offers\n",
    "            total_used_sum.append(current_used_count)\n",
    "        used_count_avg.append(np.average(total_used_sum))\n",
    "    used_count_avgs['This year' if(not year) else 'Last year'] = used_count_avg\n",
    "\n",
    "# now use the averages to compute our metrics\n",
    "# also take out the current used count, list price, and new price\n",
    "used_count_metrics = pd.DataFrame()\n",
    "used_count_per_change = []\n",
    "used_count_diff = []\n",
    "current_used_count = []\n",
    "current_list_price = []\n",
    "current_new_price = []\n",
    "current_used_price = []\n",
    "for book in range(len(book_data)) :\n",
    "    per_change = (used_count_avgs['This year'][book] - \n",
    "                  used_count_avgs['Last year'][book]) / used_count_avgs['Last year'][book]\n",
    "    used_count_per_change.append(per_change)\n",
    "    used_count_diff.append(used_count_avgs['This year'][book] - used_count_avgs['Last year'][book])\n",
    "    cur_used = book_data[book]['data']['COUNT_USED'][-1]\n",
    "    current_used_count.append(0 if cur_used == -1 else cur_used)\n",
    "    if(np.isnan(book_data[book]['data']['NEW'][-1])) :\n",
    "        current_new_price.append(book_data[book]['data']['NEW'][-2])\n",
    "    else :\n",
    "        current_new_price.append(book_data[book]['data']['NEW'][-1])\n",
    "    try :\n",
    "        book_data[book]['data']['LISTPRICE']\n",
    "        if(np.isnan(book_data[book]['data']['LISTPRICE'][-1])) :\n",
    "            current_list_price.append(current_new_price[book])\n",
    "        else :\n",
    "            current_list_price.append(book_data[book]['data']['LISTPRICE'][-1])\n",
    "    except KeyError :\n",
    "        current_list_price.append(current_new_price[book])\n",
    "    current_used_price.append(book_data[book]['data']['USED'][-1])\n",
    "    \n",
    "used_count_metrics['USED_COUNT percent change'] = used_count_per_change\n",
    "used_count_metrics['USED_COUNT difference'] = used_count_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# % ROI from current used price + shipping (see below) compared to average \n",
    "# price it sold at (or during peak?) minus Amazon ($10+15%) fees\n",
    "# for current used price (how much we pay) add $3.99 for below $5.46 and $2 for between that and $10\n",
    "\n",
    "# adjust each price it sold at for Amazon fees, counting anything less than $10 as not selling\n",
    "# Sum up the Amazon-fee-adjusted prices it sold at\n",
    "# add shipping to current used price\n",
    "# calculate adjusted ROI\n",
    "\n",
    "\n",
    "# create the function for deducting Amazon fees (15% + $10 flat fee)\n",
    "Amazon_fees = lambda price : price - (price * .15) - 10\n",
    "\n",
    "Amazon_fees(11.77) # below this it calculates lost money\n",
    "\n",
    "# make function for adding shipping costs to cheaper books\n",
    "def add_shipping(price) :\n",
    "    if price < 5.46 :\n",
    "        return(price + 3.99)\n",
    "    elif price < 10 :\n",
    "        return(price + 2)\n",
    "    else :\n",
    "        return price\n",
    "\n",
    "# Calculate the total money the book made after Amazon fees in the past year\n",
    "past_year = datetime.datetime.now() - relativedelta(years=1)\n",
    "psuedo_roi = []\n",
    "for book in sell_dates.columns :\n",
    "    recently = np.where(sell_dates[book] > past_year)[0]\n",
    "    total_revenue = np.sum(Amazon_fees(sell_prices[book][recently]))\n",
    "    used_price = add_shipping(current_used_price[book])\n",
    "    fake_roi = (total_revenue - used_price) / used_price\n",
    "    psuedo_roi.append(fake_roi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max trade-in value over the past year\n",
    "max_trade_in = []\n",
    "for book in range(len(book_data)) :\n",
    "    try :\n",
    "        last_365 = np.where(book_data[book]['data']['TRADE_IN_time'] > past_year)[0]\n",
    "        trade_in_data = np.nan_to_num(book_data[book]['data']['TRADE_IN'][last_365])\n",
    "        max_trade_in.append(np.amax(trade_in_data))\n",
    "    except :\n",
    "        max_trade_in.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = pd.DataFrame({'Psuedo ROI': psuedo_roi, \n",
    "                        'USED COUNT % change': used_count_metrics['USED_COUNT percent change'],\n",
    "                        'USED COUNT difference': used_count_metrics['USED_COUNT difference'],\n",
    "                        'CURRENT USED COUNT': current_used_count,\n",
    "                        'CURRENT LIST PRICE': current_list_price,\n",
    "                        'CURRENT NEW PRICE': current_new_price,\n",
    "                        'Max Trade-in Value': max_trade_in,\n",
    "                        'Cyclicity': variance\n",
    "                       })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Psuedo ROI</th>\n",
       "      <th>USED COUNT % change</th>\n",
       "      <th>USED COUNT difference</th>\n",
       "      <th>CURRENT USED COUNT</th>\n",
       "      <th>CURRENT LIST PRICE</th>\n",
       "      <th>CURRENT NEW PRICE</th>\n",
       "      <th>Max Trade-in Value</th>\n",
       "      <th>Cyclicity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29.899625</td>\n",
       "      <td>-0.409320</td>\n",
       "      <td>-5.416667</td>\n",
       "      <td>6</td>\n",
       "      <td>9.99</td>\n",
       "      <td>9.99</td>\n",
       "      <td>20.28</td>\n",
       "      <td>2.063728e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29.275429</td>\n",
       "      <td>-0.117171</td>\n",
       "      <td>-2.494444</td>\n",
       "      <td>14</td>\n",
       "      <td>109.99</td>\n",
       "      <td>81.88</td>\n",
       "      <td>22.07</td>\n",
       "      <td>1.635822e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.055833</td>\n",
       "      <td>-0.329189</td>\n",
       "      <td>-8.677778</td>\n",
       "      <td>12</td>\n",
       "      <td>140.00</td>\n",
       "      <td>114.38</td>\n",
       "      <td>13.99</td>\n",
       "      <td>1.693074e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50.540350</td>\n",
       "      <td>0.586141</td>\n",
       "      <td>5.122222</td>\n",
       "      <td>10</td>\n",
       "      <td>193.00</td>\n",
       "      <td>661.14</td>\n",
       "      <td>48.70</td>\n",
       "      <td>1.841261e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>135.150500</td>\n",
       "      <td>-0.334997</td>\n",
       "      <td>-9.694444</td>\n",
       "      <td>18</td>\n",
       "      <td>196.95</td>\n",
       "      <td>338.78</td>\n",
       "      <td>30.06</td>\n",
       "      <td>1.457532e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>145.917293</td>\n",
       "      <td>12.989362</td>\n",
       "      <td>6.783333</td>\n",
       "      <td>0</td>\n",
       "      <td>160.83</td>\n",
       "      <td>160.83</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.634347e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>18.472545</td>\n",
       "      <td>-0.638104</td>\n",
       "      <td>-7.777778</td>\n",
       "      <td>1</td>\n",
       "      <td>147.08</td>\n",
       "      <td>147.08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.537788e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>34.518312</td>\n",
       "      <td>-0.665167</td>\n",
       "      <td>-11.500000</td>\n",
       "      <td>3</td>\n",
       "      <td>87.95</td>\n",
       "      <td>48.00</td>\n",
       "      <td>12.96</td>\n",
       "      <td>9.102914e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>22.206250</td>\n",
       "      <td>-0.540338</td>\n",
       "      <td>-11.200000</td>\n",
       "      <td>6</td>\n",
       "      <td>208.21</td>\n",
       "      <td>208.21</td>\n",
       "      <td>15.17</td>\n",
       "      <td>9.224949e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>16.660000</td>\n",
       "      <td>-0.649985</td>\n",
       "      <td>-24.172222</td>\n",
       "      <td>12</td>\n",
       "      <td>95.00</td>\n",
       "      <td>67.84</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.420069e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Psuedo ROI  USED COUNT % change  USED COUNT difference  CURRENT USED COUNT  \\\n",
       "0   29.899625            -0.409320              -5.416667                   6   \n",
       "1   29.275429            -0.117171              -2.494444                  14   \n",
       "2   12.055833            -0.329189              -8.677778                  12   \n",
       "3   50.540350             0.586141               5.122222                  10   \n",
       "4  135.150500            -0.334997              -9.694444                  18   \n",
       "5  145.917293            12.989362               6.783333                   0   \n",
       "6   18.472545            -0.638104              -7.777778                   1   \n",
       "7   34.518312            -0.665167             -11.500000                   3   \n",
       "8   22.206250            -0.540338             -11.200000                   6   \n",
       "9   16.660000            -0.649985             -24.172222                  12   \n",
       "\n",
       "   CURRENT LIST PRICE  CURRENT NEW PRICE  Max Trade-in Value     Cyclicity  \n",
       "0                9.99               9.99               20.28  2.063728e+06  \n",
       "1              109.99              81.88               22.07  1.635822e+06  \n",
       "2              140.00             114.38               13.99  1.693074e+06  \n",
       "3              193.00             661.14               48.70  1.841261e+07  \n",
       "4              196.95             338.78               30.06  1.457532e+08  \n",
       "5              160.83             160.83                0.00  7.634347e+06  \n",
       "6              147.08             147.08                0.00  8.537788e+05  \n",
       "7               87.95              48.00               12.96  9.102914e+05  \n",
       "8              208.21             208.21               15.17  9.224949e+05  \n",
       "9               95.00              67.84                0.00  1.420069e+06  "
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now train the model\n",
    "regr = linear_model.LinearRegression()\n",
    "X = metrics\n",
    "y = [#put the subjective 'scores' in here]\n",
    "regr.fit(X,y)\n",
    "regr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Questions for Mark ~ \n",
    "# what can knowing the used offer count when it sold be good for?\n",
    "# If a book sold many times at a low value, that's not bad, but only slightly good right?\n",
    "# We care more about how much a book can sell in a year than in a peak period right?\n",
    "# So really we should calculate the sum total it made after Amazon fees in the past year then use that to compute the ROI\n",
    "# compare to the current priced + shipping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the value/worth of it to us and expected value ~ compare it with current price\n",
    "# when doing exp val if less than $10 just counts as not selling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Peak Amount</th>\n",
       "      <th>Peak End Date</th>\n",
       "      <th>Num Sold During Peak</th>\n",
       "      <th>Average # of Used Offers</th>\n",
       "      <th>Average Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>192.10</td>\n",
       "      <td>2020-02-23</td>\n",
       "      <td>5</td>\n",
       "      <td>10.800000</td>\n",
       "      <td>38.420000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>130.23</td>\n",
       "      <td>2019-06-16</td>\n",
       "      <td>3</td>\n",
       "      <td>22.333333</td>\n",
       "      <td>43.410000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>136.78</td>\n",
       "      <td>2020-02-16</td>\n",
       "      <td>3</td>\n",
       "      <td>18.333333</td>\n",
       "      <td>45.593333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>394.05</td>\n",
       "      <td>2020-02-03</td>\n",
       "      <td>3</td>\n",
       "      <td>17.333333</td>\n",
       "      <td>131.350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1884.72</td>\n",
       "      <td>2020-02-12</td>\n",
       "      <td>38</td>\n",
       "      <td>17.447368</td>\n",
       "      <td>49.597895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>372.35</td>\n",
       "      <td>2019-09-21</td>\n",
       "      <td>3</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>124.116667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>126.08</td>\n",
       "      <td>2020-05-03</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>126.080000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>205.12</td>\n",
       "      <td>2020-02-08</td>\n",
       "      <td>5</td>\n",
       "      <td>13.400000</td>\n",
       "      <td>41.024000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>179.50</td>\n",
       "      <td>2019-11-24</td>\n",
       "      <td>2</td>\n",
       "      <td>13.500000</td>\n",
       "      <td>89.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>138.00</td>\n",
       "      <td>2020-01-12</td>\n",
       "      <td>3</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>46.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Peak Amount Peak End Date  Num Sold During Peak  Average # of Used Offers  \\\n",
       "0       192.10    2020-02-23                     5                 10.800000   \n",
       "1       130.23    2019-06-16                     3                 22.333333   \n",
       "2       136.78    2020-02-16                     3                 18.333333   \n",
       "3       394.05    2020-02-03                     3                 17.333333   \n",
       "4      1884.72    2020-02-12                    38                 17.447368   \n",
       "5       372.35    2019-09-21                     3                  4.666667   \n",
       "6       126.08    2020-05-03                     1                  1.000000   \n",
       "7       205.12    2020-02-08                     5                 13.400000   \n",
       "8       179.50    2019-11-24                     2                 13.500000   \n",
       "9       138.00    2020-01-12                     3                 16.000000   \n",
       "\n",
       "   Average Price  \n",
       "0      38.420000  \n",
       "1      43.410000  \n",
       "2      45.593333  \n",
       "3     131.350000  \n",
       "4      49.597895  \n",
       "5     124.116667  \n",
       "6     126.080000  \n",
       "7      41.024000  \n",
       "8      89.750000  \n",
       "9      46.000000  "
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Peak Amount</th>\n",
       "      <th>End Date</th>\n",
       "      <th>Amount Sold</th>\n",
       "      <th>Avg # of Used Offers</th>\n",
       "      <th>Average Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>125.45</td>\n",
       "      <td>2019-02-26</td>\n",
       "      <td>1</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>125.450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186.46</td>\n",
       "      <td>2018-06-20</td>\n",
       "      <td>3</td>\n",
       "      <td>26.333333</td>\n",
       "      <td>62.153333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>175.18</td>\n",
       "      <td>2019-02-13</td>\n",
       "      <td>3</td>\n",
       "      <td>25.333333</td>\n",
       "      <td>58.393333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>350.00</td>\n",
       "      <td>2019-02-01</td>\n",
       "      <td>5</td>\n",
       "      <td>11.200000</td>\n",
       "      <td>70.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1734.22</td>\n",
       "      <td>2019-02-08</td>\n",
       "      <td>45</td>\n",
       "      <td>30.422222</td>\n",
       "      <td>38.538222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>376.55</td>\n",
       "      <td>2018-09-23</td>\n",
       "      <td>3</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>125.516667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>111.20</td>\n",
       "      <td>2019-05-10</td>\n",
       "      <td>2</td>\n",
       "      <td>14.500000</td>\n",
       "      <td>55.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20.97</td>\n",
       "      <td>2019-03-07</td>\n",
       "      <td>1</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>20.970000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.00</td>\n",
       "      <td>2020-05-03</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>99.94</td>\n",
       "      <td>2019-01-17</td>\n",
       "      <td>2</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>49.970000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Peak Amount   End Date  Amount Sold  Avg # of Used Offers  Average Price\n",
       "0       125.45 2019-02-26            1             13.000000     125.450000\n",
       "1       186.46 2018-06-20            3             26.333333      62.153333\n",
       "2       175.18 2019-02-13            3             25.333333      58.393333\n",
       "3       350.00 2019-02-01            5             11.200000      70.000000\n",
       "4      1734.22 2019-02-08           45             30.422222      38.538222\n",
       "5       376.55 2018-09-23            3              2.000000     125.516667\n",
       "6       111.20 2019-05-10            2             14.500000      55.600000\n",
       "7        20.97 2019-03-07            1             16.000000      20.970000\n",
       "8         0.00 2020-05-03            0              0.000000       0.000000\n",
       "9        99.94 2019-01-17            2             13.000000      49.970000"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_peak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# we can then create a graph of the likelyhood it will sell in that peak period at that given price\n",
    "# ((probability it will sell) * (the price it would have sold at - Amazon fees) - (used price + shipping)) / (used pric+shipng)\n",
    "\n",
    "# we set lambda to be the number of times it sold in that period times a discount factor   \n",
    "lambdas = []\n",
    "discount_factor = 0.8 # the demand for any book this year will descrease by an estimated 20%\n",
    "for book in range(len(book_data)) :\n",
    "    lambdas.append(peaks['Num Sold During Peak'][book] * discount_factor)\n",
    "\n",
    "# given that a book sold, probability that it was our book that sold and not someone else's\n",
    "def prob_our_book(used_count) :\n",
    "    return .9 - (.13 * np.sqrt(used_count))\n",
    "\n",
    "# given a certain lambda and given the probability that it was our book that sold, now find the probability that \n",
    "# the book sold during the peak period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the same peaks table for the peak 2 years ago\n",
    "old_peak = pd.DataFrame()\n",
    "new_peak_amt = []\n",
    "new_peak_date = []\n",
    "peak_num_sold = []\n",
    "pk_used_avg = []\n",
    "pk_avg_price = []\n",
    "for book in range(len(book_data)) :\n",
    "    date = peaks['Peak End Date'][book] - relativedelta(years=1)\n",
    "    date_index = np.where(date_range == date)[0][0]\n",
    "    new_peak_amt.append(np.amax(rolling_averages[book][date_index - 5:date_index + 5])) ######\n",
    "    peak_end_index = np.where(rolling_averages[book] == new_peak_amt[book])[0][-1]\n",
    "    new_peak_date.append(date_range[peak_end_index])\n",
    "    peak_num_sold.append(num_sold[book][peak_end_index])\n",
    "    pk_used_avg.append(used_count_avg[book][peak_end_index])\n",
    "    pk_avg_price.append((new_peak_amt[book] / peak_num_sold[book]) if peak_num_sold[book] != 0 else 0)\n",
    "old_peak['Peak Amount'] = new_peak_amt\n",
    "old_peak['End Date'] = new_peak_date\n",
    "old_peak['Amount Sold'] = peak_num_sold\n",
    "old_peak['Avg # of Used Offers'] = pk_used_avg\n",
    "old_peak['Average Price'] = pk_avg_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_value = []\n",
    "roi = []\n",
    "asin = []\n",
    "rankings = pd.DataFrame()\n",
    "for book in range(len(book_data)) :\n",
    "    x = 0\n",
    "    lam = lambdas[book]\n",
    "    probs = pd.DataFrame()\n",
    "    p = prob_our_book(current_used_count[book])\n",
    "    while(stats.poisson.pmf(x, lam) >= .01) :\n",
    "        dist = stats.binom(x, p)\n",
    "        prob = []\n",
    "        for trial in range(x + 1) :\n",
    "            prob.append(dist.pmf(trial) * stats.poisson.pmf(x, p))\n",
    "        probs = probs.append(pd.Series(prob), ignore_index=True)\n",
    "        x += 1\n",
    "    num_sold_probs = []\n",
    "    for num in range(len(probs.columns)) :\n",
    "        num_sold_probs.append(np.sum(probs[num]))\n",
    "    book_value.append(Amazon_fees(peaks['Average Price'][book]) * np.sum(num_sold_probs[1:]))\n",
    "    roi.append((book_value[book] - current_used_price[book]) / current_used_price[book])\n",
    "    asin.append(book_data[book]['asin'])\n",
    "rankings['ROI'] = roi\n",
    "rankings['ASIN'] = asin\n",
    "rankings = rankings.sort_values(by='ROI', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rankings.head(100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
